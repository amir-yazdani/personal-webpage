<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amir Yazdani on Amir Yazdani</title>
    <link>https://amir-yazdani.github.io/</link>
    <description>Recent content in Amir Yazdani on Amir Yazdani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>News</title>
      <link>https://amir-yazdani.github.io/full_news/</link>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://amir-yazdani.github.io/full_news/</guid>
      <description>&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Date&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;July 2021&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://amir-yazdani.github.io/files/papers/RSS2021_R4P_paper.pdf&#34; target=&#34;_blank&#34;&gt;Short paper&lt;/a&gt; got accepted to RSS 2021 workshop &lt;a href=&#34;https://sites.google.com/view/r4p2021/&#34; target=&#34;_blank&#34;&gt;Robotics For People: Perspectives on Interaction, Learning and Safety&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;June 2021&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.10586&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt; got accepted to IEEE CASE 2021.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;April 2021&lt;/td&gt;
&lt;td&gt;Had an invited talk about my research for &lt;a href=&#34;https://team.inria.fr/larsen/&#34; target=&#34;_blank&#34;&gt;LARSEN&lt;/a&gt; team at INRIA Nancy on April 8.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;April 2021&lt;/td&gt;
&lt;td&gt;Selected as the US General Chair of HRI Pioneers 2022, Sapporo, Japan.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;March 2021&lt;/td&gt;
&lt;td&gt;Presented my work on Ergonomically Intelligent Teleoperation Systems in HRI Pioneers 2021 Poster Session at HRI 2021 conference. Check the &lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3434074.3446350&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt; and &lt;a href=&#34;https://amir-yazdani.github.io/files/papers/HRI-Pioneers2021-poster.pdf&#34; target=&#34;_blank&#34;&gt;Poster&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;February 2021&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.08124&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt; got accepted to ICRA 2021. Check the &lt;a href=&#34;https://youtu.be/WmYb1sxsIjg&#34; target=&#34;_blank&#34;&gt;video&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/view/risk-aware-decision-making/home&#34; target=&#34;_blank&#34;&gt;paper website&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;February 2021&lt;/td&gt;
&lt;td&gt;Check out our recently-published paper on IJRR website: &lt;a href=&#34;https://journals.sagepub.com/doi/full/10.1177/0278364921992793&#34; target=&#34;_blank&#34;&gt;A Model Predictive Approach for Online Mobile Manipulation of Non-Holonomic Objects Using Learned Dynamics&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;December 2020&lt;/td&gt;
&lt;td&gt;Been awarded as &lt;a href=&#34;http://www.hripioneers.info/hri21/&#34; target=&#34;_blank&#34;&gt;HRI Pioneers 2021&lt;/a&gt; for my PhD research.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;December 2020&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://journals.sagepub.com/doi/full/10.1177/0278364921992793&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt; got accepted to &lt;a href=&#34;https://journals.sagepub.com/home/ijr&#34; target=&#34;_blank&#34;&gt;IJRR&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;May 2019&lt;/td&gt;
&lt;td&gt;Spending the summer 2019 at &lt;a href=&#34;https://www.adept.com/&#34; target=&#34;_blank&#34;&gt;Omron-Adept Research Center of America (ORCA)&lt;/a&gt; in San Ramon, CA as a Robotic Research Intern&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;May 2019&lt;/td&gt;
&lt;td&gt;Passed my PhD Proposal&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;April 2019&lt;/td&gt;
&lt;td&gt;Received the 2019 Dr. Paul Richards&amp;rsquo;s Safe Workplace &lt;a href=&#34;https://ergo.mech.utah.edu/2019/04/18/2019-paul-s-richards-wcf-safe-workplace-scholarship/&#34; target=&#34;_blank&#34;&gt;Scholarship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;April 2019&lt;/td&gt;
&lt;td&gt;Received the 2019 ASSP Foundation Scholarship&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;October 2018&lt;/td&gt;
&lt;td&gt;An &lt;a href=&#34;https://amir-yazdani.github.io/files/papers/NOIRS2018-AmirYazdani.pdf&#34; target=&#34;_blank&#34;&gt;abstract&lt;/a&gt; presented in NOIRS 2018, Morgantown, WV&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;October 2018&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://amir-yazdani.github.io/files/papers/sabbagh-iros-2018-dynamics-learning.pdf&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt; presented in IROS 2018, Mardid, Spain&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;April 2018&lt;/td&gt;
&lt;td&gt;Received the 2018 ASSP Foundation Scholarship&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;May 2018&lt;/td&gt;
&lt;td&gt;Received the 2018 Dr. Paul Richards&amp;rsquo;s Safe Workplace Scholarship&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;July 2017&lt;/td&gt;
&lt;td&gt;Poster presented in  ICAMPAM 2018, Bethesda, MD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;May 2017&lt;/td&gt;
&lt;td&gt;Received the 2017 Dr. Paul Richards&amp;rsquo;s Safe Workplace Scholarship&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;May 2017&lt;/td&gt;
&lt;td&gt;Abstract presented in 2017 NIOSH State of The Science Conference, Aurora, CO&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;May 2017&lt;/td&gt;
&lt;td&gt;Abstract presented in NORA 2017, Salt Lake City, UT&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;July 2016&lt;/td&gt;
&lt;td&gt;Received the $6,500 NIOSH Pilot Project grant from RMCOEH&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Installing openpose on Ubuntu 20.04</title>
      <link>https://amir-yazdani.github.io/post/openpose/</link>
      <pubDate>Sun, 18 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/post/openpose/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/CMU-Perceptual-Computing-Lab/openpose&#34; target=&#34;_blank&#34;&gt;OpenPose&lt;/a&gt; has represented the first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images.&lt;/p&gt;

&lt;p&gt;The install guide on its website, it starts with dependencies that should be installed before installing openpose. &amp;ldquo;&lt;strong&gt;DO NOT FOLLOW IT!&lt;/strong&gt;&amp;rdquo;. Instead, follow these steps:&lt;/p&gt;

&lt;p&gt;1) check your Nvidia driver version in &lt;em&gt;additional drivers&lt;/em&gt; page on your ubuntu. Make sure it is one of the proprietary packages.



&lt;figure&gt;

&lt;img src=&#34;openpose1.jpg&#34; /&gt;


&lt;/figure&gt;
2) Check your CUDA version using&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nvcc --version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If CUDA is not installed, install nvidia toolkit using&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install nvidia-cuda-toolkit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and reboot.
3) Download a version of cuDNN from &lt;a href=&#34;https://developer.nvidia.com/rdp/cudnn-archive&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; that matches your CUDA version. Download all the .deb files for runtime and developer modes and code samples.



&lt;figure&gt;

&lt;img src=&#34;openpose2.jpg&#34; /&gt;


&lt;/figure&gt;
Install the runtime and developer ones, then install the code samples.
4) Test if cuDNN using the mnist dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp -r /usr/src/cudnn_samples_v8/ $HOME
cd  $HOME/cudnn_samples_v8/mnistCUDNN
make clean &amp;amp;&amp;amp; make
chmod +x ./mnistCUDNN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If cuDNN is properly installed and running on your Linux system, you will see a message saying test passed!&lt;/p&gt;

&lt;p&gt;5) Install opencv&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install libopencv-dev python3-opencv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6) Install and configure gcc version 8 as the default using info from this &lt;a href=&#34;https://linuxize.com/post/how-to-install-gcc-on-ubuntu-20-04/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt; . Check the gcc version and make sure it is version 8.&lt;/p&gt;

&lt;p&gt;7)Now, clone openpose from the github&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;8) Install OpenPose dependencies by running the shell script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd openpose\scripts\ubuntu
chmod +x install_deps.sh
sudo ./install_deps.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will install all the dependencies except caffe. caffe source code is already in openpose &lt;code&gt;3rdparty&lt;/code&gt; folder. When you build openpose, caffe will be installed.&lt;/p&gt;

&lt;p&gt;9) Configure and make the build for OpenPose:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd {OpenPose_folder}
mkdir build/
cd build/
cmake-gui ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;select the configs you want. Make sure to check build caffe, use cuDNN and openCV. Hit &amp;lsquo;Configure&amp;rsquo; and then &amp;lsquo;Generate&amp;rsquo;. Then close cmake.&lt;/p&gt;

&lt;p&gt;10) Build OpenPose&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd build/
make -j5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;11) Now, you can run a demo using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ..
./build/examples/openpose/openpose.bin --video examples/media/video.avi
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>DULA: A Differentiable Ergonomics Model for Postural Optimization in Physical HRI</title>
      <link>https://amir-yazdani.github.io/talk/rss2021_r4p/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/rss2021_r4p/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DULA: A Differentiable Ergonomics Model for Postural Optimization in Physical HRI?</title>
      <link>https://amir-yazdani.github.io/publication/rss2021-r4p-dula/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/rss2021-r4p-dula/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Invited Talk: Ergonomically Intelligent Teleoperation Systems</title>
      <link>https://amir-yazdani.github.io/talk/inria/</link>
      <pubDate>Thu, 08 Apr 2021 08:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/inria/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Is The Leader Robot an Adequate Sensor for Posture Estimation and Ergonomic Assessment of A Human Teleoperator?</title>
      <link>https://amir-yazdani.github.io/publication/case2021-posture-estimation/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/case2021-posture-estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posture Estimation and Optimization in Ergonomically Intelligent Teleoperation Systems</title>
      <link>https://amir-yazdani.github.io/publication/hri-pioneers2021-intelligent-teleop/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/hri-pioneers2021-intelligent-teleop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posture Estimation and Optimization in Ergonomically Intelligent Teleoperation Systems</title>
      <link>https://amir-yazdani.github.io/talk/hri_pioneers2021/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/hri_pioneers2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Risk-Aware Decision Making in Service Robots to Minimize Risk of Patient Falls in Hospitals</title>
      <link>https://amir-yazdani.github.io/publication/icra-riskaware/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/icra-riskaware/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Risk-Aware Planning for Patient Fall Prevention</title>
      <link>https://amir-yazdani.github.io/project/risk_aware_planning/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/risk_aware_planning/</guid>
      <description>&lt;p&gt;In order to assist the patient efficiently, we develop a risk-aware planning framework which finds the best manipulation plan that minimizes the fall risk probability with minimum robot effort.
We view the risk-aware planning problem from the perspective of probabilistic inference and solve it as a multi-objective optimization problem.
For the fall risk objective, we use a linear combination of expected value and CVaR to minimize the overall risk of fall while avoiding even low probabilities of high fall risks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Optimization in Teleoperation</title>
      <link>https://amir-yazdani.github.io/project/pose_optimization/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pose_optimization/</guid>
      <description>&lt;p&gt;Although  teleoperation  is  a  promising  alternative to avoid injuries in high-risk tasks, awkward postures are still a primary contributor to works-related musculoskeletal disorders in teleoperation.   An   ergonomically   intelligent   teleoperation system  could  reduce  risk  by  providing  feedback  for  postural correction.  In  this  project,  we  introduce  a  novel  framework for  postural  optimization  in  teleoperation  that  benefits  from common  risk  assessment  tools  in  ergonomics  and  provides online postural correction as well as optimal initial posture correction for a teleoperator according to the type of teleoperation task. We evaluate our framework in a simulated teleoperation environment  including  the  robots  and  the  human.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Model Predictive Approach for Online Mobile Manipulation of Nonholonomic Objects using Learned Dynamics</title>
      <link>https://amir-yazdani.github.io/publication/ijrr2019-mobile-manipulation/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/ijrr2019-mobile-manipulation/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;model_comparison.PNG&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Final displacement errors with and without feedback.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;sim_results.PNG&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The final position and orientation errors in simulation experiments for all objects through all tasks.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;real_results.PNG&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Physical experiments results from two tasks.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Installing pykdl_utils on ROS</title>
      <link>https://amir-yazdani.github.io/post/pykdl/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/post/pykdl/</guid>
      <description>

&lt;h1 id=&#34;installing-guide&#34;&gt;Installing Guide :&lt;/h1&gt;

&lt;h2 id=&#34;python-2-for-ubuntu-16-04-18-04-with-ros-kinetic-melodic&#34;&gt;Python 2 for Ubuntu 16.04/18.04 with ROS Kinetic/Melodic&lt;/h2&gt;

&lt;p&gt;1) move to your catkin workspace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws/src/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2) clone the &lt;code&gt;hrl_kdl&lt;/code&gt; repository&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/gt-ros-pkg/hrl-kdl.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3) install &lt;code&gt;pykd_utils&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd hrl-kdl/pykdl_utils
python setup.py build
sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4) install &lt;code&gt;hrl_geom&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws/src/hrl-kdl/hrl_geom/
python setup.py build
sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5) install &lt;code&gt;urdf_parser&lt;/code&gt; and &lt;code&gt;urdfdom-py&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install ros-&amp;lt;ROS distibution&amp;gt;-urdf-parser-plugin
sudo apt-get install ros-&amp;lt;ROS distibution&amp;gt;-urdfdom-py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6) build the catkin workspace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws
catkin build
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;python-3-for-ubuntu-20-04-with-ros-noetic&#34;&gt;Python 3 for Ubuntu 20.04 with ROS Noetic&lt;/h2&gt;

&lt;p&gt;1) move to your catkin workspace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws/src/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2) clone the &lt;code&gt;hrl_kdl&lt;/code&gt; repository&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/amir-yazdani/hrl-kdl.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3) checkout to the noetic-devel branch&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd hrl-kdl
git checkout noetic-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4) install &lt;code&gt;pykd_utils&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd pykdl_utils
python3 setup.py build
sudo python3 setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5) install &lt;code&gt;hrl_geom&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws/src/hrl-kdl/hrl_geom/
python3 setup.py build
sudo python3 setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4) install &lt;code&gt;urdf_parser&lt;/code&gt; and &lt;code&gt;urdfdom-py&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install ros-noetic-urdf-parser-plugin
sudo apt-get install ros-noetic-urdfdom-py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5) build the catkin workspace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws
catkin build
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Estimation in Teleoperation</title>
      <link>https://amir-yazdani.github.io/project/pose_estimation/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pose_estimation/</guid>
      <description>&lt;p&gt;Human posture estimation has been a challenging research problem and many solutions has been suggested for different applications. Mainly, marker-based motion capture system and markerless camera-bases systems are the most common methods to estimate human posture. Marker-based solutions are usually more accurate however they require a long preparation time for setting up markers and calibration of MoCap systems. Markerless approaches are more convenient since they does not requires attaching markers on human body. Both of those methods are based on using cameras and have many limitation in real applications.
with the recent developments in physical human-robot interaction, estimating human posture is a demanding task specially in ergonomics and safety analysis, and adaption of robot motion based on human posture and motion.
In this project we propose a novel method to estimate human posture in teleoperation. We believe that in physical interaction between human and the robot, only knowing the robot&amp;rsquo;s trajectory is adequate to estimate the human&amp;rsquo;s posture. We model the problem as a partially-observable dynamic model and use filtering and smoothing approaches to solve the problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Estimation and Ergonomics Analysis Solely from the Robot in Physical Human-Robot Interaction</title>
      <link>https://amir-yazdani.github.io/talk/nora2019/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/nora2019/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
