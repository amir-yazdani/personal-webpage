<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amir Yazdani on Amir Yazdani</title>
    <link>https://amir-yazdani.github.io/</link>
    <description>Recent content in Amir Yazdani on Amir Yazdani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0600</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Installing pykdl_utils on ROS kinetic, Ubuntu 16.04</title>
      <link>https://amir-yazdani.github.io/post/pykdl/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/post/pykdl/</guid>
      <description>&lt;p&gt;1) clone the &lt;code&gt;hrl_kdl&lt;/code&gt; repository&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/gt-ros-pkg/hrl-kdl.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2) install &lt;code&gt;pykd_utils&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd hrl-kdl/pykdl_utils
python setup.py build
sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3) install &lt;code&gt;hrl_geom&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws/src/hrl-kdl/hrl_geom/
python setup.py build
sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4) install &lt;code&gt;urdf_parser&lt;/code&gt; and &lt;code&gt;urdfdom-py&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install ros-kinetic-urdf-parser-plugin
sudo apt-get install ros-kinetic-urdfdom-py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5) build the catkin workspace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws
catkin build
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Estimation and Ergonomics Analysis Solely from the Robot in Physical Human-Robot Interaction</title>
      <link>https://amir-yazdani.github.io/talk/nora2019/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/nora2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamics Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM) Robot</title>
      <link>https://amir-yazdani.github.io/publication/iros2018-pam/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/iros2018-pam/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Search for Twitter Spam Bots</title>
      <link>https://amir-yazdani.github.io/course_project/twitter_bots/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/course_project/twitter_bots/</guid>
      <description>&lt;p&gt;Course: CS 6350 - Machine Learning&lt;/p&gt;

&lt;p&gt;This course project includes finding spammer aand bot accounts in Twitter using machine learning techniques. The dataset is provided at the &lt;a href=&#34;https://www.kaggle.com/c/uofu-ml-fall-2017&#34; target=&#34;_blank&#34;&gt;Kaggle website&lt;/a&gt; and I have compared the performance of the following algorithms:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ID3 Decision Tree&lt;/li&gt;
&lt;li&gt;CART: Classification and Regression Trees&lt;/li&gt;
&lt;li&gt;Gaussian Naive Bayes&lt;/li&gt;
&lt;li&gt;SVM&lt;/li&gt;
&lt;li&gt;Logistic Regression&lt;/li&gt;
&lt;li&gt;SVM on CART&lt;/li&gt;
&lt;li&gt;Bagged Forest CART&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The results show that Bagged Forest Cart algorith and CART has the best accuracy on finding smap account.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;twitter_table.png&#34; /&gt;


&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;twitter_accuracy.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Accuracy of different algorithms.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Improvement of Human Safety in Fault-Tolerant Human and Robot Collaboration Using Convex Optimization and Receding Horizon Control.</title>
      <link>https://amir-yazdani.github.io/talk/niosh2017/</link>
      <pubDate>Wed, 21 Jun 2017 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/niosh2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Changing Perceptions of Robotics in Industry: Recent Accomplishment in Safety and Injury Risk Reduction</title>
      <link>https://amir-yazdani.github.io/talk/robotics_seminar/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/robotics_seminar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A New Neural Gas Network Approach for Obtaining The Singularity-Free Workspace of 3-DOF Planar Parallel Manipulators</title>
      <link>https://amir-yazdani.github.io/publication/imeche2016-pgngn/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/imeche2016-pgngn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Optimal Motion Planning for Parallel Robots Via Convex Optimization and Receding Horizon.</title>
      <link>https://amir-yazdani.github.io/publication/advrobotics2016-optimal/</link>
      <pubDate>Mon, 04 Jul 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/advrobotics2016-optimal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Manipulation Planning of A Box Using A Mobile Robot</title>
      <link>https://amir-yazdani.github.io/course_project/push_planning/</link>
      <pubDate>Fri, 27 May 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/course_project/push_planning/</guid>
      <description>&lt;p&gt;Course: ME CS 6320- 3D Computer Vision&lt;/p&gt;

&lt;p&gt;Mobility is one of the most important factors that contributes to quality of life. Each year, about 35% of individuals over age 65 experience one or more falls. Falls are the third leading cause of chronic disability worldwide6. In this project, we tried to address the concerns with home falls with a low-cost, intelligent mobile robot that will provide mobility aids, such as a walker, in the event that it determines that risk of fall is high.&lt;/p&gt;

&lt;p&gt;As the project for Motion Planning course, a simplified version of the aforementioned bigger problem was defined in a simulation-based approach. In the proposed project, the problem includes the manipulation of a walker around an obstacle-filled area using a Roomba robot from a start position to a goal position. For simulation studies, all objects will be projected to the 2D plane. The Roomba as a circle, the walker as a box, and obstacles as simple polygons. Several assumptions for the problem have been made:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Only pushing has been used for manipulating the box.&lt;/li&gt;
&lt;li&gt;Start and goal position of the box and start position of the robot are known.&lt;/li&gt;
&lt;li&gt;Obstacles and their position are known.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The proposed approach to solve the above problem includes a high-level planner for push planning for the box and a lower level planner for motion planning of the robot. Based on what has been learned up to the point of proposal, a modified A* planning algorithm as a high-level planner in combination with RRT algorithm were proposed as the solution. The main contribution of this project is the development of a collision-free push planning algorithm for a box by a Roomba robot which includes a higher-level A* planner and a lower level RRT planner. Simulation studies have been done in Python for different environments and with different start and goal positions for the robot and box. Results reveal the ability of the algorithm to do a collision-free manipulation for the box.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;pushplanning2.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Simulation results on different environments. In left column, robot initial poses are yellow, box initial poses are red, box goal poses are green. In right column, robot path are yellow, box bath are green and visited nodes for box are red.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/SSRHkvtLvPM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/C7T5bCbeFek&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/ua2OfplkcjE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mobile Robot Visual Localization and 3D Map Generation</title>
      <link>https://amir-yazdani.github.io/course_project/mobile_localization/</link>
      <pubDate>Fri, 27 May 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/course_project/mobile_localization/</guid>
      <description>&lt;p&gt;Course: ME CS 6320- 3D Computer Vision&lt;/p&gt;

&lt;p&gt;In this project, we will implement a Visual Odometry method on a Roomba iCreate 2 which is equipped with a Microsoft Kinect RGB-D sensor for localization and map generation. Although the mobile robot is moving on a 2D plane (ground), the localization and map generation algorithms are for 3D environments, so the final results are in 3D. At the end, we will evaluate our approach by comparing resulted localization with results from robot odometry, LIDAR sensor localization, or GPS data. Finally, we made a ROS package which includes different nodes for various parts of the algorithm.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;mobile1.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Indoor localization using graph-based SLAM with Kinect, LIDAR, and robot odometry.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Double-inverted pendulum</title>
      <link>https://amir-yazdani.github.io/course_project/inv_pendulum/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/course_project/inv_pendulum/</guid>
      <description>&lt;p&gt;Course: ME EN 6240- Advanced Mechatronics&lt;/p&gt;

&lt;p&gt;Control of the unstable inverted pendulum is a common research topic in the area of Dynamics and Controls. The project goal was to design, implement and test all of the mechanical, electrical, and software systems necessary to stabilize and control a double inverted pendulum. Mechanical design was completed in Solidworks and the manufactured parts were 3D printed. Electrical signal conditioning was accomplished through passive and active componentry and then integrated to a dsPIC microcontroller.&lt;/p&gt;

&lt;p&gt;All final software was developed in MATLAB Simulink then converted to C code to be used in the dsPIC. The MATLAB development environment provides an easy to use system for future attempts at controlling the system. Swing up and control of a single inverted pendulum was successful though further controller tuning could yield a better system performance.&lt;/p&gt;

&lt;p&gt;The hardware and software for a double inverted pendulum
was successfully implemented though stable control was never
achieved. Further tuning of the LQR controller parameters would
yield a stable system.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;pend1.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The double-inverted pendulum on a cart.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;pend2.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Simulation result of the step response for the double-inverted pendulum&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Estimation in p-HRI</title>
      <link>https://amir-yazdani.github.io/project/pose_estimation/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pose_estimation/</guid>
      <description>&lt;p&gt;Human posture estimation has been a challenging research problem and many solutions has been suggested for different applications. Mainly, marker-based motion capture system and markerless camera-bases systems are the most common methods to estimate human posture. Marker-based solutions are usually more accurate however they require a long preparation time for setting up parkers and calibration of mocap systems. Markerless are more convenient since they does not requires attaching markers on human body. Both of those methods are based on using cameras and have many limitation in real applications.
with the recent developments in physical human-robot interaction, estimating human posture is a demanding task specially in ergonomics and safety analysis, and adaption of robot motion based on human posture and motion.
In this project we propose a novel method to estimate human posture in telemanipulation. We believe that in physical interaction between human and the robot, only knowing the robot&amp;rsquo;s trajectory is adequate to estimate the human&amp;rsquo;s posture. We model the problem as a partially-observable dynamic model and use filtering and smoothing approaches to solve the problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PAM: A Patient Assistant Mobile Robot for Fall Prevention</title>
      <link>https://amir-yazdani.github.io/project/pam/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pam/</guid>
      <description>&lt;p&gt;In this project we introduce a patient assistant mobile (PAM) robot to monitor patient behavior and provide a cost-effective physical presence to continuously observe a patient and the environment to prevent falls.&lt;/p&gt;

&lt;p&gt;Many common objects found inside hospital rooms and personal dwellings have legs (e.g. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. Thus, we have developed a probabilistic algorithm that learns pre-categorized object models using minimal force and motion interactions between the robot and object.&lt;/p&gt;

&lt;p&gt;We account for multiple manipulation strategies by formulating the manipulation planning as a mixed-integer convex optimization problem. The proposed manipulation framework considers the hybrid control system comprised of i) choosing which leg to grasp, and ii) continuous applied forces to move the aid.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Safe Motion Planning in Shared Autonomy</title>
      <link>https://amir-yazdani.github.io/project/safety_hri/</link>
      <pubDate>Sun, 27 Mar 2016 00:00:00 -0600</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/safety_hri/</guid>
      <description>&lt;p&gt;As human and robot collaboration become more intimate, and more intelligent robots are being used in both healthcare and manufacturing environments, the safety of humans working closely with companion or co-robots is becoming a challenging issue. As a result, there is a great need for developing improved control algorithms and better guidelines to allow humans and robots to safely work together in a synergistic fashion. The nature of human variability requires the robot to be able to learn and adapt to these changes while maintaining safety in the presence of an often unpredictable human worker.&lt;/p&gt;

&lt;p&gt;In this project, we use the algorithm we developed previously for collision-free and fault-tolerant motion planniong of serial robots and we add safety features including minimum seperation distance and relative velocity of robot and the human arm. We are also adding the motion prediction of human during normal pick and place task to improve the performanc of the motion planning algorithm in respect of both the safety and the productivity.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;safety_hri1.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The shared autonomy scenario including the fauilure in the robot&amp;rsquo;s joints.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Optimal Design and Fabrication of a 4-DOF Quattrotaar Parallel Robot with Singularity-Free Workspace by ABC and PSO Algorithms</title>
      <link>https://amir-yazdani.github.io/publication/modares2016-quattrotaar/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/modares2016-quattrotaar/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
