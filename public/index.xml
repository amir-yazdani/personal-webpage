<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amir Yazdani on Amir Yazdani</title>
    <link>https://amir-yazdani.github.io/</link>
    <description>Recent content in Amir Yazdani on Amir Yazdani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Installing openpose on Ubuntu 20.04</title>
      <link>https://amir-yazdani.github.io/post/openpose/</link>
      <pubDate>Sun, 18 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/post/openpose/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/CMU-Perceptual-Computing-Lab/openpose&#34; target=&#34;_blank&#34;&gt;OpenPose&lt;/a&gt; has represented the first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images.&lt;/p&gt;

&lt;p&gt;The install guide on its website, it starts with dependencies that should be installed before installing openpose. &amp;ldquo;&lt;strong&gt;DO NOT FOLLOW IT!&lt;/strong&gt;&amp;rdquo;. Instead, follow these steps:&lt;/p&gt;

&lt;p&gt;1) check your Nvidia driver version in &lt;em&gt;additional drivers&lt;/em&gt; page on your ubuntu. Make sure it is one of the proprietary packages.



&lt;figure&gt;

&lt;img src=&#34;openpose1.jpg&#34; /&gt;


&lt;/figure&gt;
2) Check your CUDA version using&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nvcc --version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If CUDA is not installed, install nvidia toolkit using&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install nvidia-cuda-toolkit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and reboot.
3) Download a version of cuDNN from &lt;a href=&#34;https://developer.nvidia.com/rdp/cudnn-archive&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; that matches your CUDA version. Download all the .deb files for runtime and developer modes and code samples.



&lt;figure&gt;

&lt;img src=&#34;openpose2.jpg&#34; /&gt;


&lt;/figure&gt;
Install the runtime and developer ones, then install the code samples.
4) Test if cuDNN using the mnist dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp -r /usr/src/cudnn_samples_v8/ $HOME
cd  $HOME/cudnn_samples_v8/mnistCUDNN
make clean &amp;amp;&amp;amp; make
chmod +x ./mnistCUDNN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If cuDNN is properly installed and running on your Linux system, you will see a message saying test passed!&lt;/p&gt;

&lt;p&gt;5) Install opencv&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install libopencv-dev python3-opencv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6) Install and configure gcc version 8 as the default using info from this &lt;a href=&#34;https://linuxize.com/post/how-to-install-gcc-on-ubuntu-20-04/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt; . Check the gcc version and make sure it is version 8.&lt;/p&gt;

&lt;p&gt;7)Now, clone openpose from the github&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;8) Install OpenPose dependencies by running the shell script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd openpose\scripts\ubuntu
chmod +x install_deps.sh
sudo ./install_deps.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will install all the dependencies except caffe. caffe source code is already in openpose &lt;code&gt;3rdparty&lt;/code&gt; folder. When you build openpose, caffe will be installed.&lt;/p&gt;

&lt;p&gt;9) Configure and make the build for OpenPose:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd {OpenPose_folder}
mkdir build/
cd build/
cmake-gui ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;select the configs you want. Make sure to check build caffe, use cuDNN and openCV. Hit &amp;lsquo;Configure&amp;rsquo; and then &amp;lsquo;Generate&amp;rsquo;. Then close cmake.&lt;/p&gt;

&lt;p&gt;10) Build OpenPose&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd build/
make -j5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;11) Now, you can run a demo using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ..
./build/examples/openpose/openpose.bin --video examples/media/video.avi
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>DULA: A Differentiable Ergonomics Model for Postural Optimization in Physical HRI</title>
      <link>https://amir-yazdani.github.io/talk/rss2021_r4p/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/rss2021_r4p/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DULA: A Differentiable Ergonomics Model for Postural Optimization in Physical HRI?</title>
      <link>https://amir-yazdani.github.io/publication/rss2021-r4p-dula/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/rss2021-r4p-dula/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Invited Talk: Ergonomically Intelligent Teleoperation Systems</title>
      <link>https://amir-yazdani.github.io/talk/inria/</link>
      <pubDate>Thu, 08 Apr 2021 08:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/inria/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Is The Leader Robot an Adequate Sensor for Posture Estimation and Ergonomic Assessment of A Human Teleoperator?</title>
      <link>https://amir-yazdani.github.io/publication/case2021-posture-estimation/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/case2021-posture-estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posture Estimation and Optimization in Ergonomically Intelligent Teleoperation Systems</title>
      <link>https://amir-yazdani.github.io/publication/hri-pioneers2021-intelligent-teleop/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/hri-pioneers2021-intelligent-teleop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posture Estimation and Optimization in Ergonomically Intelligent Teleoperation Systems</title>
      <link>https://amir-yazdani.github.io/talk/hri_pioneers2021/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/hri_pioneers2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Risk-Aware Decision Making in Service Robots to Minimize Risk of Patient Falls in Hospitals</title>
      <link>https://amir-yazdani.github.io/publication/icra-riskaware/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/icra-riskaware/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Risk-Aware Planning for Patient Fall Prevention</title>
      <link>https://amir-yazdani.github.io/project/risk_aware_planning/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/risk_aware_planning/</guid>
      <description>&lt;p&gt;In order to assist the patient efficiently, we develop a risk-aware planning framework which finds the best manipulation plan that minimizes the fall risk probability with minimum robot effort.
We view the risk-aware planning problem from the perspective of probabilistic inference and solve it as a multi-objective optimization problem.
For the fall risk objective, we use a linear combination of expected value and CVaR to minimize the overall risk of fall while avoiding even low probabilities of high fall risks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Optimization in Teleoperation</title>
      <link>https://amir-yazdani.github.io/project/pose_optimization/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pose_optimization/</guid>
      <description>&lt;p&gt;Although  teleoperation  is  a  promising  alternative to avoid injuries in high-risk tasks, awkward postures are still a primary contributor to works-related musculoskeletal disorders in teleoperation.   An   ergonomically   intelligent   teleoperation system  could  reduce  risk  by  providing  feedback  for  postural correction.  In  this  project,  we  introduce  a  novel  framework for  postural  optimization  in  teleoperation  that  benefits  from common  risk  assessment  tools  in  ergonomics  and  provides online postural correction as well as optimal initial posture correction for a teleoperator according to the type of teleoperation task. We evaluate our framework in a simulated teleoperation environment  including  the  robots  and  the  human.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Model Predictive Approach for Online Mobile Manipulation of Nonholonomic Objects using Learned Dynamics</title>
      <link>https://amir-yazdani.github.io/publication/ijrr2019-mobile-manipulation/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0800</pubDate>
      
      <guid>https://amir-yazdani.github.io/publication/ijrr2019-mobile-manipulation/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;model_comparison.PNG&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Final displacement errors with and without feedback.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;sim_results.PNG&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The final position and orientation errors in simulation experiments for all objects through all tasks.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;real_results.PNG&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Physical experiments results from two tasks.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Installing pykdl_utils on ROS kinetic, Ubuntu 16.04</title>
      <link>https://amir-yazdani.github.io/post/pykdl/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/post/pykdl/</guid>
      <description>&lt;p&gt;1) clone the &lt;code&gt;hrl_kdl&lt;/code&gt; repository&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/gt-ros-pkg/hrl-kdl.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2) install &lt;code&gt;pykd_utils&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd hrl-kdl/pykdl_utils
python setup.py build
sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3) install &lt;code&gt;hrl_geom&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws/src/hrl-kdl/hrl_geom/
python setup.py build
sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4) install &lt;code&gt;urdf_parser&lt;/code&gt; and &lt;code&gt;urdfdom-py&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install ros-kinetic-urdf-parser-plugin
sudo apt-get install ros-kinetic-urdfdom-py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5) build the catkin workspace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/catkin_ws
catkin build
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Estimation in Teleoperation</title>
      <link>https://amir-yazdani.github.io/project/pose_estimation/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pose_estimation/</guid>
      <description>&lt;p&gt;Human posture estimation has been a challenging research problem and many solutions has been suggested for different applications. Mainly, marker-based motion capture system and markerless camera-bases systems are the most common methods to estimate human posture. Marker-based solutions are usually more accurate however they require a long preparation time for setting up markers and calibration of MoCap systems. Markerless approaches are more convenient since they does not requires attaching markers on human body. Both of those methods are based on using cameras and have many limitation in real applications.
with the recent developments in physical human-robot interaction, estimating human posture is a demanding task specially in ergonomics and safety analysis, and adaption of robot motion based on human posture and motion.
In this project we propose a novel method to estimate human posture in teleoperation. We believe that in physical interaction between human and the robot, only knowing the robot&amp;rsquo;s trajectory is adequate to estimate the human&amp;rsquo;s posture. We model the problem as a partially-observable dynamic model and use filtering and smoothing approaches to solve the problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Posture Estimation and Ergonomics Analysis Solely from the Robot in Physical Human-Robot Interaction</title>
      <link>https://amir-yazdani.github.io/talk/nora2019/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/talk/nora2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mobile Manipulation Planning</title>
      <link>https://amir-yazdani.github.io/project/pam/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 -0700</pubDate>
      
      <guid>https://amir-yazdani.github.io/project/pam/</guid>
      <description>&lt;p&gt;In this project we introduce a patient assistant mobile (PAM) robot to monitor patient behavior and provide a cost-effective physical presence to continuously observe a patient and the environment to prevent falls.&lt;/p&gt;

&lt;p&gt;Many common objects found inside hospital rooms and personal dwellings have legs (e.g. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. Thus, we have developed a probabilistic algorithm that learns pre-categorized object models using minimal force and motion interactions between the robot and object.&lt;/p&gt;

&lt;p&gt;We account for multiple manipulation strategies by formulating the manipulation planning as a mixed-integer convex optimization problem. The proposed manipulation framework considers the hybrid control system comprised of i) choosing which leg to grasp, and ii) continuous applied forces to move the aid.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
